import pandas as pd
from scipy.stats import gmean
import os
import torch
import argparse
from colorama import Fore, Style
import re
import sys
import random
import string
import math
from cuda.bindings.driver import cuDeviceGetAttribute, CUdevice_attribute
from cuda.bindings import driver

from bitgen.from_icgrep import (
    run_regex_kernel,
    compile_regex,
    compile_regex_group_list,
    compile_xml,
    load_input_stream
)
from bitgen.bitstream import transpose_bytestream_to_bitstream
from bitgen.tool.timer import global_timer
from bitgen.tool.pcre import read_regex_from_pcre_file
import bitgen.config as cfg
from bitgen.log import MyLogger


def split_input(input_stream_tensor: torch.tensor, split_input_num: int):
    if split_input_num < 1:
        return input_stream_tensor
    if split_input_num == 1:
        return input_stream_tensor.unsqueeze(0)
    raise NotImplementedError
    if input_stream_tensor.size(0) % split_input_num != 0:
        reduced_size = (
            input_stream_tensor.size(0) - input_stream_tensor.size(0) % split_input_num
        )
        input_stream_tensor = input_stream_tensor[:reduced_size]
        print(
            f"split_input: input_stream size ({input_stream_tensor.shape}) can't be divided by split_input_num {split_input_num}, reduced to {reduced_size}"
        )
    split_size = input_stream_tensor.size(0) // split_input_num
    split_input_stream_tensor = input_stream_tensor.view(split_input_num, split_size)
    print(
        f"split_input: Split input stream tensor by {split_input_num}: from {input_stream_tensor.shape} to {split_input_stream_tensor.shape}"
    )
    return split_input_stream_tensor


def select_regex(regexes, regex_num=-1, random_select=False):
    if regex_num > 0:
        if random_select:
            print(
                f"Random select {regex_num} regexes from file ({len(regexes)} regexes)"
            )
            random.seed(42)
            regexes = random.sample(regexes, regex_num)
        else:
            print(f"Select {regex_num} regexes from file ({len(regexes)} regexes)")
            regexes = regexes[:regex_num]
    return regexes


def select_regex_from_file(regex_file, regex_num=-1, random_select=False):
    regexes = read_regex_from_pcre_file(regex_file)
    regexes = select_regex(regexes, regex_num, random_select)
    return regexes


def group_regex_in_list(regex_list, regex_group_number, multi_input):
    assert isinstance(regex_list, list)
    if regex_group_number >= 1:
        if regex_group_number > len(regex_list):
            regex_group_number = len(regex_list)
        regex_group_list = balance_regex_groups(regex_list, regex_group_number)
        # for regex_group_id, regex_group in enumerate(regex_group_list):
        #     print(
        #         f"Regex group {regex_group_id}: regex_num={len(regex_group)}"
        #     )
        #     for regex in regex_group:
        #         print(f"    {regex}")
    else:
        regex_group_list = [[regex] for regex in regex_list]
    regex_group_list = [
        regex_group for regex_group in regex_group_list if len(regex_group) > 0
    ]
    return regex_group_list


# # Greedy algorithm generated by ChatGPT.
# def balance_regex_groups(regex_list, regex_group_number):
#     regex_list.sort(key=len, reverse=False)
#     regex_group_list = [[] for _ in range(regex_group_number)]
#     group_lengths = [0] * regex_group_number
#     for regex in regex_list:
#         min_index = group_lengths.index(min(group_lengths))
#         regex_group_list[min_index].append(regex)
#         group_lengths[min_index] += len(regex)
#     return regex_group_list

def regex_custom_length(regex):
    regex = re.sub(r'\\x[0-9A-Fa-f]{2}', 'X', regex)
    regex = re.sub(r'\[[^\]]+\]', 'Y', regex)
    return len(regex)

def balance_regex_groups(regex_list, regex_group_number):
    regex_list.sort(key=regex_custom_length)
    regex_group_list = [[] for _ in range(regex_group_number)]
    group_lengths = [0] * regex_group_number
    for regex in regex_list:
        length = regex_custom_length(regex)
        min_index = group_lengths.index(min(group_lengths))
        regex_group_list[min_index].append(regex)
        group_lengths[min_index] += length
    return regex_group_list

# def balance_regex_groups(regex_list, regex_group_number):
#     regex_list.sort(key=len, reverse=False)
#     regex_group_size = math.ceil(len(regex_list) / regex_group_number)
#     regex_group_list = [[] for _ in range(regex_group_number)]
#     remain_regex_num = regex_group_size * regex_group_number - len(regex_list)
#     compeleted_group = regex_group_number - remain_regex_num
#     compeleted_regex_start = compeleted_group * regex_group_size
#     for group_id in range(regex_group_number):
#         if group_id < compeleted_group:
#             regex_group_list[group_id] = regex_list[
#                 group_id * regex_group_size : (group_id + 1) * regex_group_size
#             ]
#         else:
#             regex_group_list[group_id] = regex_list[
#                 compeleted_regex_start
#                 + (group_id - compeleted_group)
#                 * (regex_group_size - 1) : compeleted_regex_start
#                 + (group_id - compeleted_group + 1) * (regex_group_size - 1)
#             ]
#     return regex_group_list


def run_bitgen_group_list(
    regex_group_list, input_path, input_stream_tensor, basic_stream_tensor
):
    assert isinstance(regex_group_list, list)
    assert isinstance(regex_group_list[0], list)

    print(
        f"Regex group list info: regex_num={sum([len(group) for group in regex_group_list])}, list_size = {len(regex_group_list)}, group_size = {len(regex_group_list[0])}"
    )
    if cfg.get_config("regex_group_serial"):
        for regex_group_id, regex_group in enumerate(regex_group_list):
            global_timer.set_group("regex_group_" + str(regex_group_id))
            regex_group = [regex_group]
            kernel_path = compile_regex_group_list(
                regex_group,
                input_path,
                input_stream_tensor,
                basic_stream_tensor,
            )
            if not cfg.get_config("dry_run"):
                print(f"Run regex group {regex_group_id}")
                run_regex_kernel(
                    kernel_path,
                    regex_group,
                    input_path,
                    input_stream_tensor,
                    basic_stream_tensor,
                )
    else:
        kernel_path = compile_regex_group_list(
            regex_group_list,
            input_path,
            input_stream_tensor,
            basic_stream_tensor,
        )
        if not cfg.get_config("dry_run"):
            run_regex_kernel(
                kernel_path,
                regex_group_list,
                input_path,
                input_stream_tensor,
                basic_stream_tensor,
            )


def run_bitgen_str(regex, input_path, input_stream_tensor, basic_stream_tensor):
    assert isinstance(regex, str)
    kernel_path = compile_regex(
        regex,
        input_path,
        input_stream_tensor,
        basic_stream_tensor,
    )
    if not cfg.get_config("dry_run"):
        run_regex_kernel(
            kernel_path,
            regex,
            input_path,
            input_stream_tensor,
            basic_stream_tensor,
        )

def run_xml(input_path, input_stream_tensor, basic_stream_tensor):
    kernel_path = compile_xml(
        "xml_parser",
        input_path,
        input_stream_tensor,
        basic_stream_tensor,
    )
    if not cfg.get_config("dry_run"):
        run_regex_kernel(
            kernel_path,
            "xml_parser",
            input_path,
            input_stream_tensor,
            basic_stream_tensor,
        )

def run_bitgen(input_path, regex, regex_from_file=False, is_xml = False):
    # Load input stream
    input_stream = load_input_stream(input_path)

    # Limit input stream length
    input_size = cfg.get_config("input_size")
    if input_size:
        MyLogger.info(f"[Inputstream]: Limit input stream length to {input_size} bytes")
        input_stream = input_stream[:input_size]
    input_stream_tensor = torch.ByteTensor(list(input_stream))

    # Replicate input stream
    repeat_input_num = cfg.get_config("repeat_input")
    if repeat_input_num > 1:
        original_shape = input_stream_tensor.size()
        input_stream_tensor = input_stream_tensor.repeat(repeat_input_num)
        new_shape = input_stream_tensor.size()
        MyLogger.info(
            f"[Inputstream]: Repeat input stream tensor {repeat_input_num} times: from {original_shape} to {new_shape}"
        )

    # Simulate multiple input streams
    multi_input = cfg.get_config("multi_input")
    if multi_input >= 1:
        input_stream_tensor = input_stream_tensor.repeat(multi_input, 1)
        MyLogger.info(
            f"[Inputstream]: Multiple input_stream_tensor shape: {input_stream_tensor.shape}"
        )

    # Split input stream
    split_input_num = cfg.get_config("split_input")
    if split_input_num:
        input_stream_tensor = split_input(input_stream_tensor, split_input_num)
        MyLogger.info(
            f"[Inputstream]: Split input_stream_tensor shape: {input_stream_tensor.shape}"
        )
        # raise NotImplementedError

    # Transpose input stream to bitstream
    print("Transpose")
    basic_stream_tensor = transpose_bytestream_to_bitstream(input_stream_tensor)
    basic_stream_tensor = basic_stream_tensor.cuda()
    print("basic_stream_tensor shape:", basic_stream_tensor.shape)
    # Shape meaning: (split_input_num, multi_input, 8, bitstream_size)

    if is_xml:
        print("XML parsing")
        run_xml(input_path, input_stream_tensor, basic_stream_tensor)
    elif regex_from_file:
        # List of regex from regex file
        regex_list = select_regex_from_file(
            regex,
            regex_num=cfg.get_config("regex_num"),
            random_select=False,
        )
        regex_group_list = group_regex_in_list(
            regex_list,
            regex_group_number=cfg.get_config("regex_group_number"),
            multi_input=multi_input,
        )
        run_bitgen_group_list(
            regex_group_list, input_path, input_stream_tensor, basic_stream_tensor
        )
    else:
        # Regex string
        assert isinstance(regex, str)
        print("Regex string")
        run_bitgen_str(
            regex,
            input_path,
            input_stream_tensor,
            basic_stream_tensor,
        )


def main():
    args_parser = argparse.ArgumentParser(
        description="Benchmarking automata-compiler",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    args_parser.add_argument(
        "--backend",
        default="cuda",
        type=str,
        choices=["cuda", "torch"],
        help="Backend.",
    )

    # Execution config
    args_parser.add_argument(
        "--warmup_iters",
        default=4,
        type=int,
        help="Number of warmup iterations.",
    )
    args_parser.add_argument(
        "--exec_iters",
        default=8,
        type=int,
        help="Number of execution iterations.",
    )
    args_parser.add_argument(
        "--dry_run",
        default=0,
        type=int,
        help="Dry run. Only compile the regex.",
    )
        

    # Regex config
    args_group = args_parser.add_mutually_exclusive_group(required=True)
    args_group.add_argument("-e", "--regex", default="", type=str, help="Regex string.")
    args_group.add_argument(
        "-f", "--regex_file", default="", type=str, help="Regex file path."
    )
    args_group.add_argument(
        "--xml",
        default=False,
        action="store_true",
        help="xml parsing",
    )
    args_parser.add_argument(
        "--regex_num_from_file",
        default=-1,
        type=int,
        help="Number of regexes. Only used for regex file.",
    )
    args_parser.add_argument(
        "--regex_group_number",
        default=1,
        type=int,
        help="Number of regex groups.",
    )
    args_parser.add_argument(
        "--regex_group_serial",
        default=0,
        type=int,
        help="Run regex group in serial. (for bug)",
    )
    # args_parser.add_argument(
    #     "--balance_regex_groups",
    #     default=1,
    #     type=int,
    #     help="Balance regex groups based on the length",
    # )

    # Input config
    args_parser.add_argument(
        "-i",
        "--input_file",
        default="",
        type=str,
        required=True,
        help="Input file path.",
    )
    args_parser.add_argument(
        "--input-size",
        default=-1,
        type=int,
        help="Limit the input size in bytes.",
    )
    args_parser.add_argument(
        "--repeat-input",
        default=1,
        type=int,
        help="Repeat the input stream.",
    )
    args_parser.add_argument(
        "--multi-input",
        default=1,
        type=int,
        help="Number of input streams.",
    )
    args_parser.add_argument(
        "--split-input",
        default=1,
        type=int,
        help="Split the input stream into several parts and launch the kernel multiple times.",
    )

    # Compilation config
    args_parser.add_argument(
        "--parallel_compile_parabix",
        default=1,
        type=int,
        help="Compile parabix in parallel.",
    )
    args_parser.add_argument(
        "--parallel_compile_cuda",
        default=1,
        type=int,
        help="Compile cuda in parallel.",
    )
    args_parser.add_argument(
        "--parallel_compile_cuda_lto",
        default=0,
        type=int,
        help="Enable LTO for cuda parallel compilation.",
    )
    args_parser.add_argument(
        "--pass-cc-advanced",
        default=0,
        type=int,
        help="Enable advanced CC pass.",
    )
    args_parser.add_argument(
        "--pass-cc-advanced-max",
        default=1,
        type=int,
        help="Max number of block to be stored in shared memory in advanced CC pass. 0: no limit with glabal memory",
    )
    args_parser.add_argument(
        "--pass-cc-advanced-merge-cc",
        default=1,
        type=int,
        help="Merge CC in advanced CC pass.",
    )
    args_parser.add_argument(
        "--pass-short-circuit",
        default=0,
        type=int,
        help="Enable short circuit pass.",
    )
    args_parser.add_argument(
        "--pass-short-circuit-start",
        default=2,
        type=int,
        help="Position to start inserting short circuit.",
    )
    args_parser.add_argument(
        "--pass-short-circuit-interval",
        default=2,
        type=int,
        help="Interval to insert short circuit.",
    )
    args_parser.add_argument(
        "--pass-short-circuit-interval-disable",
        default=0,
        type=int,
        help="Interval to insert short circuit.",
    )
    args_parser.add_argument(
        "--pass-short-circuit-syncpoint",
        default=1,
        type=int,
        help="Insert sync point in short circuit pass",
    )
    # args_parser.add_argument(
    #     "--pass-loop-peeling",
    #     default=0,
    #     type=int,
    #     help="Enable loop peeling pass.",
    # )
    args_parser.add_argument(
        "--pass-graph-break",
        default=0,
        choices=[-1, 0, 1, 2],
        type=int,
        help="Insert graph break in insts. -1: dynamic adv offset to fuse while loop, 0: not insert, 1: insert between insts, 2: insert between adv, scanthru, and while.",
    )
    args_parser.add_argument(
        "--pass-print-graph",
        default=0,
        type=int,
        help="Print graph.",
    )
    args_parser.add_argument(
        "--pass-inst-stats",
        default=0,
        type=int,
        help="Print inst stats.",
    )
    args_parser.add_argument(
        "--pass-inst-stats-dyn",
        default=0,
        type=int,
        help="Print inst stats.",
    )

    args_parser.add_argument(
        "--cuda-register-num",
        default=128,
        type=int,
        help="Number of registers per thread.",
    )
    
    args_parser.add_argument(
        "--cuda_block_size",
        default=512,
        type=int,
        help="Number of threads per block.",
    )
    
    

    # Debug config
    args_parser.add_argument(
        "-c", "--check", default=0, type=int, help="Validate the result."
    )
    args_parser.add_argument(
        "-r",
        "--reuse_cache",
        default=False,
        action="store_true",
        help="Reuse cached code.",
    )

    # Torch
    args_parser.add_argument(
        "--torch-compile",
        default=0,
        type=int,
        help="Compile regex with pytorch.",
    )

    args = args_parser.parse_args()

    # Execution config
    cfg.set_config("warmup_iters", args.warmup_iters)
    cfg.set_config("exec_iters", args.exec_iters)
    cfg.set_config("dry_run", args.dry_run)

    # Regex config
    cfg.set_config("regex_num", args.regex_num_from_file)
    cfg.set_config("regex_group_number", args.regex_group_number)
    cfg.set_config("regex_group_serial", args.regex_group_serial)
    # cfg.set_config("balance_regex_groups", args.balance_regex_groups)

    # Input config
    cfg.set_config("input_size", args.input_size)
    cfg.set_config("repeat_input", args.repeat_input)
    cfg.set_config("multi_input", args.multi_input)
    cfg.set_config("split_input", args.split_input)

    #  Compilation config
    cfg.set_config("pass_cc_advanced", args.pass_cc_advanced)
    cfg.set_config("pass_cc_advanced_max", args.pass_cc_advanced_max)
    cfg.set_config("pass_cc_advanced_merge_cc", args.pass_cc_advanced_merge_cc)
    cfg.set_config("pass_short_circuit", args.pass_short_circuit)
    cfg.set_config("pass_short_circuit_start", args.pass_short_circuit_start)
    cfg.set_config("pass_short_circuit_interval", args.pass_short_circuit_interval)
    cfg.set_config("pass_short_circuit_interval_disable", args.pass_short_circuit_interval_disable)
    cfg.set_config("pass_short_circuit_syncpoint", args.pass_short_circuit_syncpoint)
    # cfg.set_config("pass_loop_peeling", args.pass_loop_peeling)
    cfg.set_config("pass_graph_break", args.pass_graph_break)
    cfg.set_config("pass_print_graph", args.pass_print_graph)
    cfg.set_config("pass_inst_stats", args.pass_inst_stats)
    cfg.set_config("pass_inst_stats_dyn", args.pass_inst_stats_dyn)
    cfg.set_config("parallel_compile_parabix", args.parallel_compile_parabix)
    cfg.set_config("parallel_compile_cuda", args.parallel_compile_cuda)
    cfg.set_config("parallel_compile_cuda_lto", args.parallel_compile_cuda_lto)

    cfg.set_config("backend", args.backend)

    # Backend config: CUDA
    cfg.set_config("block_size", (args.cuda_block_size, 1, 1))
    cfg.set_config("cuda_register_num", args.cuda_register_num)

    # Backend config: Torch
    cfg.set_config("torch_compile", args.torch_compile)
    cfg.set_config("debug_torch", 0)

    # Debug config
    # cfg.set_config("profile", True)
    # cfg.set_config("print_bitstream", True)
    # cfg.set_config("print_bit_start", 0)
    # cfg.set_config("print_zeros", True)
    cfg.set_config("validation", args.check)
    cfg.set_config("use_cached_code", args.reuse_cache)
    # cfg.set_config("cached_code_dir", ".cache_bitgen")

    cfg.print_config()

    regex = args.regex if args.regex else args.regex_file
    input_file = args.input_file
    run_bitgen(input_file, regex, regex_from_file=bool(args.regex_file), is_xml = args.xml)


if __name__ == "__main__":
    try:
        global_timer.reset_timings()
        main()
    finally:
        global_timer.display_timings()
        result_path = os.path.join(os.environ["BITGEN_ROOT"], "raw_results/ac")
        global_timer.save_to_file(result_path)
        global_timer.reset_timings()
        if hasattr(global_timer, "inst_result"):
            df = pd.DataFrame(global_timer.inst_result.items(), columns=["inst", "count"])
            print(df)
